{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "figured-piece",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gini/sylve057/.conda/envs/llm_env/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/home/gini/sylve057/.conda/envs/llm_env/lib/python3.9/site-packages/huggingface_hub/file_download.py:1003: UserWarning: Not enough free disk space to download the file. The expected file size is: 548.11 MB. The target location /home/gini/sylve057/.cache/huggingface/hub only has 520.14 MB free disk space.\n",
      "  warnings.warn(\n",
      "/home/gini/sylve057/.conda/envs/llm_env/lib/python3.9/site-packages/huggingface_hub/file_download.py:1003: UserWarning: Not enough free disk space to download the file. The expected file size is: 548.11 MB. The target location /home/gini/sylve057/.cache/huggingface/hub/models--gpt2/blobs only has 520.14 MB free disk space.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from transformers import GPT2LMHeadModel, GPT2Tokenizer\n",
    "\n",
    "tokenizer = GPT2Tokenizer.from_pretrained('gpt2')  \n",
    "model = GPT2LMHeadModel.from_pretrained('gpt2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "relevant-amount",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hi?\n",
      "\n",
      "I'm not sure if you're aware of the fact that the US government has been using the term \"global warming\" to describe the global warming that is happening in the US.\n",
      "\n",
      "The US government has been using the term \"global warming\" to describe the global warming that is happening in the US.\n",
      "\n",
      "The US government has been using the term \"global warming\" to describe the global warming that is happening in the US.\n",
      "\n",
      "The US government has been using\n"
     ]
    }
   ],
   "source": [
    "input_text = \"Hi?\"\n",
    "\n",
    "input_ids = tokenizer.encode(input_text, return_tensors='pt')\n",
    "\n",
    "output = model.generate(input_ids, max_length=100)\n",
    "\n",
    "print(tokenizer.decode(output[0], skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "banned-amazon",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (llm_env)",
   "language": "python",
   "name": "llm_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
